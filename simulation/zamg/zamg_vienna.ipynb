{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "\n",
    "matplotlib.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "sns.set_theme()\n",
    "plt.rcParams.update({\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "    'pgf.preamble': '\\\\usepackage{lmodern}',\n",
    "})\n",
    "\n",
    "frames = [\n",
    "    pd.read_csv(Path.cwd().joinpath('data/vienna_20100101_20131231.csv'), index_col='time', parse_dates=True),\n",
    "    pd.read_csv(Path.cwd().joinpath('data/vienna_20140101_20171231.csv'), index_col='time', parse_dates=True),\n",
    "    pd.read_csv(Path.cwd().joinpath('data/vienna_20180101_20211231.csv'), index_col='time', parse_dates=True)\n",
    "]\n",
    "df = pd.concat(frames)\n",
    "df.index = df.index.tz_convert(None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_column_values(df: pd.DataFrame) -> [str]:\n",
    "    # returns a list of all columns in the dataframe that contain only one unique value (i.e. all rows are equal)\n",
    "    # cf. https://stackoverflow.com/a/54405767\n",
    "    def is_unique(s: pd.Series):\n",
    "        a = s.to_numpy()\n",
    "        return (a[0] == a).all()\n",
    "\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if is_unique(df[col]):\n",
    "            print(f'Column {col} has only a single value: {df[col][0]}')\n",
    "            result.append(col)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_duplicate_indices(df: Union[pd.DataFrame, pd.Series]) -> Union[pd.DataFrame, pd.Series]:\n",
    "    duplicates = df[df.index.duplicated(keep=False)]\n",
    "    if duplicates.empty:\n",
    "        print('There are no duplicate indices')\n",
    "        return df\n",
    "    print('Duplicated indices:')\n",
    "    print(duplicates.index)\n",
    "\n",
    "    remove = df.index.duplicated(keep='last')\n",
    "    return df[~remove]\n",
    "\n",
    "\n",
    "# Remove columns without any information and duplicate indices\n",
    "df.drop(columns=get_unique_column_values(df), inplace=True)\n",
    "df = remove_duplicate_indices(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict the air temperature measurements 2m above ground (\"TL\").\n",
    "Possible input attributes are air temperature (TL), air pressure (P), reduced air pressure (P0), wind direction (DD), mean wind speed (FFAM), relative humidity (RF), precipitation (RR), sun shine duration (SO), and dew point (TP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first, we check whether the index is indeed complete (every 10 minutes)\n",
    "print(f'Dataset ranging from {df.index.min()} to {df.index.max()} in 10-minute steps:')\n",
    "(df.index == pd.date_range(df.index.min(), df.index.max(), freq='10min')).all(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's see how complete the data is\n",
    "df[df.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['TL'].plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we have many gaps due to incomplete reduced air pressure (P0)\n",
    "# if we remove the column, we halve the number of measurements with missing values\n",
    "without_p0 = df.drop(columns=['P0', 'P0_FLAG'])\n",
    "df[without_p0.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# another suspect of many missing values is the dew point (TP)\n",
    "# then we suddenly only remain with 0.3% missing values\n",
    "df = without_p0\n",
    "without_tp = df.drop(columns=['TP', 'TP_FLAG'])\n",
    "df[without_tp.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for small gaps (up to 3 hours) we use simple linear interpolation\n",
    "df = without_tp\n",
    "df = df.interpolate(method='linear', limit=17, limit_area='inside')\n",
    "gaps = df[df.isna().any(axis=1)]\n",
    "gaps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we still have some bigger gaps in the data concentrated on a few days\n",
    "# interpolation is not sufficient, as we cannot interpolate over a gap of multiple days.\n",
    "gap_days = gaps.index.map(pd.Timestamp.date).unique()\n",
    "print('Missing values on :')\n",
    "for day in gap_days:\n",
    "    daily = df.loc[str(day)]\n",
    "    missing = daily[daily.isna().any(axis=1)]\n",
    "    print(f'{day}: {len(missing)}\\t(={len(missing) / (60 / 10 * 24) * 100:.2f}%)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's look at the gaps one after another\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def extend_gap(gap: slice, delta: timedelta):\n",
    "    return slice(datetime.fromisoformat(gap.start) - delta, datetime.fromisoformat(gap.stop) + delta)\n",
    "\n",
    "\n",
    "# the first one has only missing precipitation\n",
    "gap = slice('2010-07-29 15:40:00', '2010-07-30 09:50:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=4)), 'RR'].plot()\n",
    "plt.show()\n",
    "# it is reasonable to let it stop raining\n",
    "df.loc[gap, 'RR'] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# next is again a precipitation gap\n",
    "gap = slice('2011-10-07 13:30:00', '2011-10-08 00:00:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=6)), ['RR']].plot()\n",
    "plt.show()\n",
    "# again, we can safely assume it stopped raining\n",
    "df.loc[gap, ['RR']] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# another precipitation gap\n",
    "gap = slice('2011-10-09 09:20:00', '2011-10-09 12:10:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=6)), ['RR']].plot()\n",
    "plt.show()\n",
    "# probably hasn't rained\n",
    "df.loc[gap, ['RR']] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the next one is a bigger wind direction + speed gap\n",
    "gap = slice('2014-11-29 11:10:00', '2014-12-01 10:40:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=72)), ['DD', 'FFAM']].plot()\n",
    "plt.show()\n",
    "# let's just re-use the last 24 hours over the period\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    df.loc[dt, ['DD', 'FFAM']] = df.loc[dt - timedelta(hours=24), ['DD', 'FFAM']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gap = slice('2017-04-02 02:00:00', '2017-04-02 05:00:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=24)), ['DD', 'FFAM', 'P']].plot()\n",
    "plt.show()\n",
    "# linear interpolation should be fine also here\n",
    "df.loc[extend_gap(gap, timedelta(hours=1))] = df.loc[extend_gap(gap, timedelta(hours=1))].interpolate(method='linear',\n",
    "                                                                                                      limit=10,\n",
    "                                                                                                      limit_area='inside')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gap = slice('2017-04-04 07:40:00', '2017-04-04 14:10:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=48)), ['DD', 'FFAM']].plot()\n",
    "plt.show()\n",
    "# wind has not changed significantly, let's repeat the past 4 hours\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    df.loc[dt, ['DD', 'FFAM']] = df.loc[dt - timedelta(hours=4), ['DD', 'FFAM']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now we have the biggest gap in the data\n",
    "# %matplotlib qt\n",
    "gap = slice('2017-04-05 23:50:00', '2017-04-09 23:50:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=144))].plot()\n",
    "plt.show()\n",
    "# we cannot identify a significant weather change in these 4 days, hence we repeat the last 4 days\n",
    "# only the wind direction has shifted a bit, but we would not know how to represent this in the data\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    past_hours = [24, 48, 72]\n",
    "    df.loc[dt] = 0\n",
    "    for h in past_hours:\n",
    "        df.loc[dt] += df.loc[dt - timedelta(h)]\n",
    "    df.loc[dt] /= len(past_hours)\n",
    "# %matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gap = slice('2018-04-01 06:10:00', '2018-04-03 05:40:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=144)), ['DD', 'FFAM']].plot()\n",
    "plt.show()\n",
    "# three days ago a similar pattern occurred, we fill it up\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    past_hours = [24, 48, 72]\n",
    "    df.loc[dt] = 0\n",
    "    for h in past_hours:\n",
    "        df.loc[dt] += df.loc[dt - timedelta(h)]\n",
    "    df.loc[dt] /= len(past_hours)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# and finally the COVID gap\n",
    "gap = slice('2020-03-13 20:10:00', '2020-03-15 12:40:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=144))].plot()\n",
    "plt.show()\n",
    "# we take the averages of the past three days\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    past_hours = [24, 48, 72]\n",
    "    df.loc[dt] = 0\n",
    "    for h in past_hours:\n",
    "        df.loc[dt] += df.loc[dt - timedelta(h)]\n",
    "    df.loc[dt] /= len(past_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a simple plausibility check of the final data (flag values above 300 indicate a potential faulty measurement)\n",
    "df[(df['TL'] < -15) | (df['TL'] > 40) | (df['TL_FLAG'] > 300) | (df['RF_FLAG'] > 300) | (df['P_FLAG'] > 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the remaining flag attributes and arrive at a dataset without null values\n",
    "df.drop(columns=['DD_FLAG', 'FFAM_FLAG', 'P_FLAG', 'RF_FLAG', 'RR_FLAG', 'SO_FLAG', 'TL_FLAG'], inplace=True)\n",
    "print(f'Remaining NaN values: {df[df.isna().any(axis=1)]}')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we need to encode the degrees of the wind direction: 360° should be close to 0°\n",
    "df.loc[:, 'DD_sin'] = np.sin(df.loc[:, 'DD'] * np.pi / 180)\n",
    "df.loc[:, 'DD_cos'] = np.cos(df.loc[:, 'DD'] * np.pi / 180)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# in the correlation matrix we see that all attributes are quite unique\n",
    "df.corr()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_pickle(Path.cwd().joinpath('zamg_vienna.pickle'))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# when we sample hourly data we need to sum up the sunshine duration and precipitation for 1 hour\n",
    "df['SO'] = df['SO'].rolling(6).sum()\n",
    "df['RR'] = df['RR'].rolling(6).sum()\n",
    "df = df.iloc[6:, :]  # remove created NaN entries (start with next full hour)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# be aware that precipitation is a very skewed distribution\n",
    "# most of the time it is not raining, but sometimes it rains a lot\n",
    "print(df['RR'].describe())\n",
    "df['RR'].plot.box()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we create an additional variant where 'RR' is min-max normalized\n",
    "# equals a MaxAbsScaler, since the minimum value is 0\n",
    "df['RR_norm'] = (df.loc[:, 'RR'] - df['RR'].min()) / (df['RR'].max() - df['RR'].min())\n",
    "print(df['RR_norm'].describe())\n",
    "df.to_pickle(Path.cwd().joinpath('zamg_vienna_hourly.pickle'))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
