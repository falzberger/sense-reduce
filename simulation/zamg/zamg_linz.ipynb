{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "\n",
    "matplotlib.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "sns.set_theme()\n",
    "plt.rcParams.update({\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "    'pgf.preamble': '\\\\usepackage{lmodern}',\n",
    "})\n",
    "\n",
    "frames = [\n",
    "    pd.read_csv(Path.cwd().joinpath('data/linz_20100101_20131231.csv'), index_col='time', parse_dates=True),\n",
    "    pd.read_csv(Path.cwd().joinpath('data/linz_20140101_20171231.csv'), index_col='time', parse_dates=True),\n",
    "    pd.read_csv(Path.cwd().joinpath('data/linz_20180101_20211231.csv'), index_col='time', parse_dates=True)\n",
    "]\n",
    "df = pd.concat(frames)\n",
    "df.index = df.index.tz_convert(None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_column_values(df: pd.DataFrame) -> [str]:\n",
    "    # returns a list of all columns in the dataframe that contain only one unique value (i.e. all rows are equal)\n",
    "    # cf. https://stackoverflow.com/a/54405767\n",
    "    def is_unique(s: pd.Series):\n",
    "        a = s.to_numpy()\n",
    "        return (a[0] == a).all()\n",
    "\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if is_unique(df[col]):\n",
    "            print(f'Column {col} has only a single value: {df[col][0]}')\n",
    "            result.append(col)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_duplicate_indices(df: Union[pd.DataFrame, pd.Series]) -> Union[pd.DataFrame, pd.Series]:\n",
    "    duplicates = df[df.index.duplicated(keep=False)]\n",
    "    if duplicates.empty:\n",
    "        print('There are no duplicate indices')\n",
    "        return df\n",
    "    print('Duplicated indices:')\n",
    "    print(duplicates.index)\n",
    "\n",
    "    remove = df.index.duplicated(keep='last')\n",
    "    return df[~remove]\n",
    "\n",
    "\n",
    "# Remove columns without any information and duplicate indices\n",
    "df.drop(columns=get_unique_column_values(df), inplace=True)\n",
    "df = remove_duplicate_indices(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict the air temperature measurements 2m above ground (\"TL\").\n",
    "Possible input attributes are air temperature (TL), air pressure (P), reduced air pressure (P0), wind direction (DD), mean wind speed (FFAM), relative humidity (RF), precipitation (RR), sun shine duration (SO), and dew point (TP).\n",
    "In the parameter study we only use air temperature, air pressure, relative humidity, and sunshine duration.\n",
    "Therefore, we remove the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first, we check whether the index is indeed complete (every 10 minutes)\n",
    "complete = (df.index == pd.date_range(df.index.min(), df.index.max(), freq='10min')).all(axis=0)\n",
    "print(f'Dataset ranging from {df.index.min()} to {df.index.max()} in 10-minute steps: {complete}')\n",
    "df = df.reindex(columns=['TL', 'TL_FLAG', 'P', 'P_FLAG', 'RF', 'RF_FLAG', 'SO', 'SO_FLAG'], copy=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TL'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we only have some missing values (~0.1%)\n",
    "df[df.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we have some small gaps for sun shine duration which we can fill with linear interpolation up to 2 hours\n",
    "df = df.interpolate(method='linear', limit=11, limit_area='inside')\n",
    "gaps = df[df.isna().any(axis=1)]\n",
    "gaps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# there's an outlier for the pressure value\n",
    "sns.boxplot(df['P'])\n",
    "df.loc['2016-11-24 14:50:00', 'P'] = 987.8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we still have some bigger gaps in the data concentrated on a few days\n",
    "# interpolation is not sufficient, as we cannot interpolate over a gap of multiple days.\n",
    "gap_days = gaps.index.map(pd.Timestamp.date).unique()\n",
    "print('Missing values on :')\n",
    "for day in gap_days:\n",
    "    daily = df.loc[str(day)]\n",
    "    missing = daily[daily.isna().any(axis=1)]\n",
    "    print(f'{day}: {len(missing)}\\t(={len(missing) / (60 / 10 * 24) * 100:.2f}%)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's look at the gaps one after another\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def extend_gap(gap: slice, delta: timedelta):\n",
    "    return slice(datetime.fromisoformat(gap.start) - delta, datetime.fromisoformat(gap.stop) + delta)\n",
    "\n",
    "\n",
    "# the first one has only missing sun shine duration\n",
    "gap = slice('2012-07-24 17:10:00', '2012-07-25 06:40:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=48)), 'SO'].plot()\n",
    "plt.show()\n",
    "# it is reasonable that the sun stopped shining at 17:10, similar to the previous day\n",
    "df.loc[gap, 'SO'] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# and then we have one big gap where all data is missing\n",
    "# %matplotlib qt\n",
    "gap = slice('2017-04-06 01:50:00', '2017-04-09 23:50:00')\n",
    "df.loc[extend_gap(gap, timedelta(hours=144))].plot()\n",
    "plt.show()\n",
    "# we cannot identify a significant weather change in these 4 days, hence we use the average of the last 3 days\n",
    "for dt in pd.date_range(gap.start, gap.stop, freq='10min'):\n",
    "    past_hours = [24, 48, 72]\n",
    "    df.loc[dt] = 0\n",
    "    for h in past_hours:\n",
    "        df.loc[dt] += df.loc[dt - timedelta(h)]\n",
    "    df.loc[dt] /= len(past_hours)\n",
    "# %matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a simple plausibility check of the final data (flag values above 300 indicate a potential faulty measurement)\n",
    "df[(df['TL'] < -15) | (df['TL'] > 40) | (df['TL_FLAG'] > 300) | (df['RF_FLAG'] > 300) | (df['P_FLAG'] > 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the remaining flag attributes and arrive at a dataset without null values\n",
    "df.drop(columns=['TL_FLAG', 'P_FLAG', 'RF_FLAG', 'SO_FLAG'], inplace=True)\n",
    "print(f'Remaining NaN values: {df[df.isna().any(axis=1)]}')\n",
    "# also check the high-level metrics whether they make sense\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# in the correlation matrix we see that all attributes are quite unique\n",
    "# the correlation between relative humidity, sunshine duration and temperature is plausible\n",
    "df.corr()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_pickle(Path.cwd().joinpath('zamg_linz.pickle'))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# when we sample hourly data we need to sum up the sunshine duration and precipitation for 1 hour\n",
    "df['SO'] = df['SO'].rolling(6).sum()\n",
    "df = df.iloc[6:, :]  # remove created NaN entries (start with next full hour)\n",
    "df.to_pickle(Path.cwd().joinpath('zamg_linz_hourly.pickle'))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's plot the yearly averages of the data\n",
    "climate: pd.Series = df['TL'].groupby([df.index.month, df.index.day]).mean()\n",
    "climate: pd.DataFrame = pd.DataFrame(columns=['TL'], data=climate.values,\n",
    "                                     index=pd.date_range('2020-01-01', '2020-12-31'))\n",
    "climate.plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first calculate the total sunshine duration per day and undo the rolling hourly sum\n",
    "daily_sunshine: pd.Series = df['SO'].groupby([df.index.year, df.index.month, df.index.day]).sum() / 6\n",
    "# then take the mean over all years\n",
    "sunshine = daily_sunshine.groupby(level=[1, 2]).mean()\n",
    "sunshine.plot()\n",
    "plt.show()\n",
    "sunshine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
